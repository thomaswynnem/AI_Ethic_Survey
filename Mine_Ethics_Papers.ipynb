{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24380841",
   "metadata": {},
   "source": [
    "### *Survey Paper:* What is the Current Research on the Ethic of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287373c2",
   "metadata": {},
   "source": [
    "#### Step 1: Pull Data From:\n",
    " * https://aclanthology.org/\n",
    " * https://www.institutional.org/institutional-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90931451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\anaconda3\\envs\\NLP\\Lib\\site-packages\\acl_anthology\\anthology.py:96: SchemaMismatchWarning: Data directory contains a different schema.rnc as this library; you might need to update the data or the acl-anthology library.\n",
      "  warnings.warn(SchemaMismatchWarning())\n"
     ]
    }
   ],
   "source": [
    "from acl_anthology import Anthology\n",
    "anthology = Anthology.from_repo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb82657",
   "metadata": {},
   "source": [
    "#### Step 2: Analysis of NLP Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6b1b8",
   "metadata": {},
   "source": [
    "##### Step 2 Part A: Load In Specter 2 Model\n",
    "\n",
    "* https://huggingface.co/allenai/specter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1adaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from typing import List\n",
    "\n",
    "class Specter2:\n",
    "    def __init__(self, model_name='allenai/specter2_base'):\n",
    "        # Load model and tokenizer upon initialization\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoAdapterModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_input(self, text_batch: List[str]):\n",
    "        # Preprocess the input and compute embeddings\n",
    "        inputs = self.tokenizer(text_batch, padding=True, truncation=True,\n",
    "                                return_tensors=\"pt\", return_token_type_ids=False, max_length=512)\n",
    "        output = self.model(**inputs)\n",
    "        embeddings = output.last_hidden_state[:, 0, :]\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04685a55",
   "metadata": {},
   "source": [
    "##### Step 2 Part B: Encode Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a10b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 29279.61it/s]\n",
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "specter2 = Specter2()\n",
    "#load the query adapter, provide an identifier for the adapter in load_as argument and activate it\n",
    "specter2.model.load_adapter(\"allenai/specter2_adhoc_query\", source=\"hf\", load_as=\"specter2_adhoc_query\", set_active=True)\n",
    "query = [\"Bidirectional transformers\"]\n",
    "query_embedding = specter2.embed_input(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d0750",
   "metadata": {},
   "source": [
    "##### Step 2 Part C: Encode Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94471c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'specter2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#load the proximity adapter, provide an identifier for the adapter in load_as argument and activate it\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mspecter2\u001b[49m.model.load_adapter(\u001b[33m\"\u001b[39m\u001b[33mallenai/specter2\u001b[39m\u001b[33m\"\u001b[39m, source=\u001b[33m\"\u001b[39m\u001b[33mhf\u001b[39m\u001b[33m\"\u001b[39m, load_as=\u001b[33m\"\u001b[39m\u001b[33mspecter2_proximity\u001b[39m\u001b[33m\"\u001b[39m, set_active=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# pull papers from anthology\u001b[39;00m\n\u001b[32m      6\u001b[39m papers = anthology.papers()\n",
      "\u001b[31mNameError\u001b[39m: name 'specter2' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "#load the proximity adapter, provide an identifier for the adapter in load_as argument and activate it\n",
    "specter2.model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"specter2_proximity\", set_active=True)\n",
    "\n",
    "# pull papers from anthology\n",
    "papers = anthology.papers()\n",
    "\n",
    "# convert papers into structured inputs -> `{Title}: {Abstract}`\n",
    "text_papers_batch = [(str(d.title) or \"\") + specter2.tokenizer.sep_token + (str(d.abstract) or \"\") for d in papers]\n",
    "paper_embeddings = specter2.embed_input(text_papers_batch)\n",
    "\n",
    "# Calculate L2 distance between query and papers\n",
    "l2_distance = euclidean_distances(paper_embeddings, query_embedding).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d86e09",
   "metadata": {},
   "source": [
    "##### Step 2 Part D: Analyze and Graph Clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
